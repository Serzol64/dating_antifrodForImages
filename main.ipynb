{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6232149,"sourceType":"datasetVersion","datasetId":2298863}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_dir = '/kaggle/input/selfies-id-images-dataset/Selfies ID Images dataset'\ntrain_dir = os.path.join(base_dir, '18_sets_ Caucasians')\nvalidation_dir = os.path.join(base_dir, '11_sets_Hispanics')\n\nimg_height = img_width = 128\nbatch_size = 64\n\ntrain_ds = image_dataset_from_directory(train_dir, seed=123, image_size=(64, 64), batch_size=batch_size)\nval_ds = image_dataset_from_directory(validation_dir, seed=123, image_size=(64, 64), batch_size=batch_size)\n\n\nmodel = Sequential([\n    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    \n    Flatten(),  # Приведение к плоской форме перед полносвязным слоем\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # Финальный выходной слой\n])\n\n\n# Показываем сводку архитектуры модели\nmodel.summary()\n\n# Определяем критерии оптимизации и компиляции модели\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.002), metrics=['accuracy'])\n\n# Добавляем раннюю остановку, чтобы избежать переобучения\nearly_stopping = EarlyStopping(monitor='val_loss', patience=6)\n\n# Начинаем процесс обучения\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=[early_stopping])\n\n# Строим график изменения потери (Loss) на этапах обучения и валидации\nplt.figure(figsize=(20, 10))\nplt.subplot(2, 3, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Потеря (Loss)')\nplt.xlabel('Эпоха')\nplt.ylabel('Ошибка')\nplt.legend()\n\n# График изменения точности (Accuracy)\nplt.subplot(2, 4, 4)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Точность (Accuracy)')\nplt.xlabel('Эпоха')\nplt.ylabel('Точность')\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Функция для прогноза одиночного изображения\ndef predict_image(image_path):\n    img = tf.keras.utils.load_img(image_path, target_size=(img_height, img_width))  # Загружаем изображение нужного размера\n    img_array = tf.keras.utils.img_to_array(img)  # Преобразуем в массив\n    img_array = tf.expand_dims(img_array, 0)  # Создаём батч (одиночное изображение)\n    prediction = model.predict(img_array)[0][0]  # Прогнозируем класс\n    return 'Подделка!' if prediction > 0.5 else 'Реальная!'\n\n# Использовать функцию predict_image для любого нового изображения\nnew_image_path = input(\"Введите ссылку на изображение(минимальная ширина фото - 128 пикселей): \")\nresult = predict_image(new_image_path)\nprint(f'Результат прогноза: {result}')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}